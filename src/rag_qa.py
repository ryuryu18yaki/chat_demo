from __future__ import annotations

from typing import List, Dict, Any, Optional
from openai import OpenAI
from src.rag_vector import query_collection
from src.rag_preprocess import extract_images_from_pdf
from base64 import b64encode

# ---------------------------------------------------------------------------
# è¨­å®š
# ---------------------------------------------------------------------------
_DEFAULT_MODEL = "gpt-4o-mini"

# ---------------------------------------------------------------------------
# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆçµ„ã¿ç«‹ã¦
# ---------------------------------------------------------------------------

def _build_prompt(question: str, contexts: List[str]) -> List[Dict[str, str]]:
    system_msg = {
        "role": "system",
        "content": (
            "You are a helpful assistant. Use the provided context to answer the "
            "user's question. If the context is insufficient, say you don't know."
        ),
    }
    context_block = "\n\n".join(f"[Doc {i+1}]\n{ctx}" for i, ctx in enumerate(contexts))
    user_msg = {
        "role": "user",
        "content": (
            f"Context:\n{context_block}\n\n"
            f"Question: {question}\n\nAnswer in Japanese."
        ),
    }
    return [system_msg, user_msg]

# ---------------------------------------------------------------------------
# å›ç­”ç”Ÿæˆ
# ---------------------------------------------------------------------------

def generate_answer(
        *,
        prompt: str,
        question: str,
        collection,
        rag_files: List[Dict[str, Any]],
        top_k: int = 5,
        model: str = _DEFAULT_MODEL,
        max_context_chars: int = 6000,
        chat_history: Optional[List[Dict[str, str]]] = None,
        temperature: Optional[float] = None,
        max_tokens: Optional[int] = None,
    ) -> Dict[str, Any]:
        """
        1) ãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã§ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢
        2) ãƒ’ãƒƒãƒˆã—ãŸãƒ†ã‚­ã‚¹ãƒˆ/è¡¨ãƒãƒ£ãƒ³ã‚¯ã‚’ contexts ã«é›†ç´„
        3) åŒãƒšãƒ¼ã‚¸ã®ç”»åƒã‚’ PDF ã‹ã‚‰åˆ‡ã‚Šå‡ºã—ã¦ files ã«è¿½åŠ 
        4) GPT-4V ã¸ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã¨ã—ã¦æ¸¡ã—å›ç­”ã‚’ç”Ÿæˆ
        """
        client = OpenAI()

        # --- 1) ãƒ†ã‚­ã‚¹ãƒˆ/è¡¨ã®ã¿ã‚’æ¤œç´¢ ---
        hits = query_collection(
            collection=collection,
            query=question,
            n_results=top_k,
        )
        
        # --- 2) contexts ã‚’åé›† ---
        contexts: List[str] = []
        total_len = 0
        for hit in hits:
            meta = hit.get("metadata", {})
            kind = meta.get("kind", "text")
            if kind not in ("text", "table"):
                continue
            content = hit.get("content", "")
            if total_len + len(content) > max_context_chars:
                break
            contexts.append(content)
            total_len += len(content)
        
        # --- 3) ç”»åƒã‚’æŠ½å‡º ---
        files: List[Dict[str, bytes]] = []
        placeholders: List[str] = []
        images_info: List[Dict[str, Any]] = []  # ğŸ”¥ ç”»åƒæƒ…å ±ã‚’ä¿å­˜
        
        for hit in hits:
            meta = hit.get("metadata", {})
            if meta.get("kind") not in ("text", "table"):
                continue
            source = meta.get("source")
            page = meta.get("page")
            if not source or not page:
                continue
            # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ã® PDF ã‹ã‚‰æŠ½å‡º
            for f in rag_files:
                if f["name"] == source:
                    for img in extract_images_from_pdf(f["data"]):
                        if img["page"] == page:
                            # ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ã‚’è¿½åŠ 
                            idx = len(placeholders) + 1
                            placeholders.append(f"[Image {idx}: {source} p{page} id={img['image_id']}]" )
                            files.append({
                                "name": f"{source}_p{page}_{img['image_id']}.png",
                                "data": img["bytes"],
                            })
                            
                            # ğŸ”¥ ç”»åƒæƒ…å ±ã‚’ä¿å­˜ï¼ˆè¡¨ç¤ºç”¨ï¼‰
                            images_info.append({
                                "name": f"{source}_p{page}_{img['image_id']}.png",
                                "data": img["bytes"],
                                "source": source,
                                "page": page,
                                "image_id": img["image_id"]
                            })
        
        # ç”»åƒã®ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ã‚’ contexts ã«è¿½åŠ 
        contexts.extend(placeholders)
        
        # --- 4) ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆçµ„ã¿ç«‹ã¦ ---
        system_msg, user_msg = _build_prompt(question, contexts)
        
        # ç”»åƒã‚’å«ã‚€ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ« user ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å½¢å¼ã«å¤‰æ›
        parts: List[Dict[str, Any]] = []
        for idx, file in enumerate(files, start=1):
            data_url = "data:image/png;base64," + b64encode(file["data"]).decode("utf-8")
            parts.append({"type": "image_url", "image_url": {"url": data_url}})
        # æœ€å¾Œã«ãƒ†ã‚­ã‚¹ãƒˆéƒ¨åˆ†ã‚’è¿½åŠ 
        parts.append({"type": "text", "text": user_msg["content"]})
        user_msg["content"] = parts
        
        # --- 5) Messages çµ„ã¿ç«‹ã¦ ---
        messages: List[Dict[str, Any]] = []
        if chat_history:
            messages.append({"role": "system", "content": prompt})
            messages.extend(chat_history)
        messages.append(system_msg)
        messages.append(user_msg)
        
        # --- 6) APIå‘¼ã³å‡ºã—ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ§‹ç¯‰ ---
        params = {
            "model": model,
            "messages": messages,
        }
        
        # temperatureã¨max_tokensãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã®ã¿è¿½åŠ 
        if temperature is not None:
            params["temperature"] = temperature
        if max_tokens is not None:
            params["max_tokens"] = max_tokens
        
        # --- 7) GPT-4V å‘¼ã³å‡ºã— ---
        resp = client.chat.completions.create(**params)
        
        # ğŸ”¥ ç”»åƒæƒ…å ±ã‚‚è¿”ã™ã‚ˆã†ã«ä¿®æ­£
        return {
            "answer": resp.choices[0].message.content,
            "sources": hits,
            "images": images_info  # ç”»åƒæƒ…å ±ã‚’è¿½åŠ 
        }