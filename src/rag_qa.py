# src/rag_qa.py - AWS Bedrock Claude + Azure OpenAI GPTç‰ˆ

from __future__ import annotations
from typing import List, Dict, Any, Optional
import boto3
import json
import os

try:
    import streamlit as st
    STREAMLIT_AVAILABLE = True
except ImportError:
    STREAMLIT_AVAILABLE = False

# Azure OpenAIé–¢é€£ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’è¿½åŠ 
try:
    from openai import AzureOpenAI
    AZURE_OPENAI_AVAILABLE = True
except ImportError:
    AZURE_OPENAI_AVAILABLE = False

# ğŸ”¥ ãƒ“ãƒ«æƒ…å ±ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’è¿½åŠ 
from src.building_manager import get_building_manager

# ---------------------------------------------------------------------------
# AWS Bedrockè¨­å®š
# ---------------------------------------------------------------------------
def create_bedrock_client():
    """AWS Bedrock ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ä½œæˆ"""
    if STREAMLIT_AVAILABLE:
        try:
            aws_access_key_id = st.secrets.get("AWS_ACCESS_KEY_ID", os.getenv("AWS_ACCESS_KEY_ID"))
            aws_secret_access_key = st.secrets.get("AWS_SECRET_ACCESS_KEY", os.getenv("AWS_SECRET_ACCESS_KEY"))
            aws_region = st.secrets.get("AWS_REGION", os.getenv("AWS_REGION", "us-east-1"))
        except:
            aws_access_key_id = os.getenv("AWS_ACCESS_KEY_ID")
            aws_secret_access_key = os.getenv("AWS_SECRET_ACCESS_KEY")
            aws_region = os.getenv("AWS_REGION", "us-east-1")
    else:
        aws_access_key_id = os.getenv("AWS_ACCESS_KEY_ID")
        aws_secret_access_key = os.getenv("AWS_SECRET_ACCESS_KEY")
        aws_region = os.getenv("AWS_REGION", "us-east-1")
    
    if not aws_access_key_id or not aws_secret_access_key:
        raise ValueError("AWS Bedrock ã®è¨­å®šãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚ç’°å¢ƒå¤‰æ•°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    
    return boto3.client(
        'bedrock-runtime',
        aws_access_key_id=aws_access_key_id,
        aws_secret_access_key=aws_secret_access_key,
        region_name=aws_region
    )

# ---------------------------------------------------------------------------
# Azure OpenAIè¨­å®š
# ---------------------------------------------------------------------------
def create_azure_client():
    """Azure OpenAI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ä½œæˆ"""
    if not AZURE_OPENAI_AVAILABLE:
        raise ValueError("Azure OpenAI ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚pip install openai ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
    
    if STREAMLIT_AVAILABLE:
        try:
            azure_endpoint = st.secrets.get("AZURE_OPENAI_ENDPOINT", os.getenv("AZURE_OPENAI_ENDPOINT"))
            azure_api_key = st.secrets.get("AZURE_OPENAI_API_KEY", os.getenv("AZURE_OPENAI_API_KEY"))
            azure_api_version = st.secrets.get("AZURE_OPENAI_API_VERSION", os.getenv("AZURE_OPENAI_API_VERSION", "2024-08-01-preview"))
        except:
            azure_endpoint = os.getenv("AZURE_OPENAI_ENDPOINT")
            azure_api_key = os.getenv("AZURE_OPENAI_API_KEY")
            azure_api_version = os.getenv("AZURE_OPENAI_API_VERSION", "2024-08-01-preview")
    else:
        azure_endpoint = os.getenv("AZURE_OPENAI_ENDPOINT")
        azure_api_key = os.getenv("AZURE_OPENAI_API_KEY")
        azure_api_version = os.getenv("AZURE_OPENAI_API_VERSION", "2024-08-01-preview")
    
    if not azure_endpoint or not azure_api_key:
        raise ValueError("Azure OpenAI ã®è¨­å®šãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚ç’°å¢ƒå¤‰æ•°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    
    return AzureOpenAI(
        azure_endpoint=azure_endpoint,
        api_key=azure_api_key,
        api_version=azure_api_version
    )

# ---------------------------------------------------------------------------
# ãƒ¢ãƒ‡ãƒ«ç®¡ç†
# ---------------------------------------------------------------------------

# Claudeç”¨ã®ãƒ¢ãƒ‡ãƒ«åãƒãƒƒãƒ”ãƒ³ã‚°
CLAUDE_MODEL_MAPPING = {
    "claude-4-sonnet": "apac.anthropic.claude-sonnet-4-20250514-v1:0",
    "claude-3.7": "apac.anthropic.claude-3-7-sonnet-20250219-v1:0"
}

# Azure OpenAIç”¨ã®ãƒ¢ãƒ‡ãƒ«åãƒãƒƒãƒ”ãƒ³ã‚°ã‚’è¿½åŠ 
AZURE_MODEL_MAPPING = {
    "gpt-4.1": "gpt-4.1",
    "gpt-4o": "gpt-4o"
}

def get_claude_model_name(model_name: str) -> str:
    """Claudeè¡¨ç¤ºåã‚’Bedrockãƒ¢ãƒ‡ãƒ«IDã«å¤‰æ›"""
    return CLAUDE_MODEL_MAPPING.get(model_name, model_name)

def call_claude_bedrock(client, model_id: str, messages: List[Dict], max_tokens: int = None, temperature: float = None):
    """AWS Bedrock Converse APIçµŒç”±ã§Claudeã‚’å‘¼ã³å‡ºã—"""
    
    # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å½¢å¼ã‚’Converse APIã«åˆã‚ã›ã¦å¤‰æ›
    system_prompts = []
    conversation_messages = []
    
    for msg in messages:
        if msg["role"] == "system":
            system_prompts.append({"text": msg["content"]})
        else:
            conversation_messages.append({
                "role": msg["role"],
                "content": [{"text": msg["content"]}]
            })
    
    # Converse APIç”¨ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ§‹ç¯‰
    converse_params = {
        "modelId": model_id,
        "messages": conversation_messages,
        "inferenceConfig": {
            "maxTokens": max_tokens or 4096  # max_tokensãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚Œã°ãã‚Œã‚’ä½¿ç”¨ã€ãªã‘ã‚Œã°4096
        }
    }
    
    # temperatureãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã®ã¿è¨­å®š
    if temperature is not None and temperature != 0.0:
        converse_params["inferenceConfig"]["temperature"] = temperature
    
    # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒã‚ã‚‹å ´åˆã¯è¿½åŠ 
    if system_prompts:
        converse_params["system"] = system_prompts
    
    # Converse APIå‘¼ã³å‡ºã—
    response = client.converse(**converse_params)
    
    return response['output']['message']['content'][0]['text']

def call_azure_gpt(client, model_name: str, messages: List[Dict], max_tokens: int = None, temperature: float = None):
    """Azure OpenAIçµŒç”±ã§GPTã‚’å‘¼ã³å‡ºã—"""
    formatted_messages = []
    
    for msg in messages:
        if msg["role"] in ["system", "user", "assistant"]:
            formatted_messages.append({
                "role": msg["role"],
                "content": msg["content"]
            })
    
    api_params = {
        "model": AZURE_MODEL_MAPPING.get(model_name, model_name),
        "messages": formatted_messages,
        "max_tokens": max_tokens or 4096  # Noneã®å ´åˆã¯4096ã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã«
    }
    
    if temperature is not None and temperature != 0.0:
        api_params["temperature"] = temperature
    
    response = client.chat.completions.create(**api_params)
    return response.choices[0].message.content

# ---------------------------------------------------------------------------
# è¨­å®š
# ---------------------------------------------------------------------------
_DEFAULT_MODEL = "claude-4-sonnet"

# ---------------------------------------------------------------------------
# å›ç­”ç”Ÿæˆï¼ˆè¨­å‚™å…¨æ–‡æŠ•å…¥ç‰ˆï¼‰
# ---------------------------------------------------------------------------

def generate_answer_with_equipment(
        *,
        prompt: str,
        question: str,
        equipment_data: Dict[str, Dict[str, Any]],
        target_equipment: str,
        selected_files: Optional[List[str]] = None,
        model: str = _DEFAULT_MODEL,
        chat_history: Optional[List[Dict[str, str]]] = None,
        temperature: Optional[float] = None,
        max_tokens: Optional[int] = None,
        include_building_info: bool = True,  # ğŸ”¥ æ–°è¦è¿½åŠ 
        target_building: Optional[str] = None,  # ğŸ”¥ æ–°è¦è¿½åŠ 
    ) -> Dict[str, Any]:
    """
    æŒ‡å®šã•ã‚ŒãŸè¨­å‚™ã®é¸æŠãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«æŠ•å…¥ã—ã¦AIã§å›ç­”ã‚’ç”Ÿæˆ
    
    Args:
        prompt: ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        question: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•
        equipment_data: è¨­å‚™ãƒ‡ãƒ¼ã‚¿è¾æ›¸ï¼ˆpreprocess_filesã®å‡ºåŠ›ï¼‰
        target_equipment: å¯¾è±¡è¨­å‚™å
        selected_files: ä½¿ç”¨ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«åã®ãƒªã‚¹ãƒˆï¼ˆNoneãªã‚‰å…¨ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰
        model: ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«
        chat_history: ãƒãƒ£ãƒƒãƒˆå±¥æ­´
        temperature: æ¸©åº¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        max_tokens: æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°
        include_building_info: ãƒ“ãƒ«æƒ…å ±ã‚’å«ã‚ã‚‹ã‹ã©ã†ã‹  # ğŸ”¥ æ–°è¦è¿½åŠ 
        target_building: å¯¾è±¡ãƒ“ãƒ«åï¼ˆNoneãªã‚‰å…¨ãƒ“ãƒ«æƒ…å ±ï¼‰  # ğŸ”¥ æ–°è¦è¿½åŠ 
    
    Returns:
        å›ç­”çµæœè¾æ›¸
    """
    
    # --- 1) æŒ‡å®šè¨­å‚™ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾— ---
    if target_equipment not in equipment_data:
        available_equipment = list(equipment_data.keys())
        raise ValueError(f"è¨­å‚™ '{target_equipment}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚åˆ©ç”¨å¯èƒ½ãªè¨­å‚™: {available_equipment}")
    
    equipment_info = equipment_data[target_equipment]
    available_files = equipment_info["files"]  # ãƒ•ã‚¡ã‚¤ãƒ«å â†’ ãƒ†ã‚­ã‚¹ãƒˆã®è¾æ›¸
    all_sources = equipment_info["sources"]
    
    # ğŸ”¥ é¸æŠã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ã‚’çµåˆ
    if selected_files is not None:
        print(f"ğŸ”§ ä½¿ç”¨è¨­å‚™: {target_equipment}")
        print(f"ğŸ“„ é¸æŠãƒ•ã‚¡ã‚¤ãƒ«: {', '.join(selected_files)}")
        print(f"ğŸ“„ åˆ©ç”¨å¯èƒ½ãƒ•ã‚¡ã‚¤ãƒ«: {', '.join(all_sources)}")
        
        # é¸æŠã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’çµåˆ
        selected_texts = []
        actual_sources = []
        
        for file_name in selected_files:
            if file_name in available_files:
                selected_texts.append(available_files[file_name])
                actual_sources.append(file_name)
            else:
                print(f"âš ï¸ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_name}")
        
        if not selected_texts:
            raise ValueError(f"é¸æŠã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ{', '.join(selected_files)}ï¼‰ãŒè¨­å‚™ãƒ‡ãƒ¼ã‚¿ã«è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        
        combined_text = "\n\n".join(selected_texts)
        sources = actual_sources
        
        print(f"ğŸ“ çµåˆå¾Œæ–‡å­—æ•°: {len(combined_text)}")
        
    else:
        # å…¨ãƒ•ã‚¡ã‚¤ãƒ«ä½¿ç”¨
        selected_texts = list(available_files.values())
        combined_text = "\n\n".join(selected_texts)
        sources = all_sources
        
        print(f"ğŸ”§ ä½¿ç”¨è¨­å‚™: {target_equipment}")
        print(f"ğŸ“„ å…¨ãƒ•ã‚¡ã‚¤ãƒ«ä½¿ç”¨: {', '.join(sources)}")
        print(f"ğŸ“ çµåˆå¾Œæ–‡å­—æ•°: {len(combined_text)}")
    
    # ğŸ”¥ --- 2) ãƒ“ãƒ«æƒ…å ±ã‚’å–å¾—ã—ã¦ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«è¿½åŠ  ---
    building_info_text = ""
    if include_building_info:
        building_manager = get_building_manager()
        if building_manager and building_manager.available:
            if target_building:
                building_info_text = building_manager.format_building_info_for_prompt(target_building)
                print(f"ğŸ¢ å¯¾è±¡ãƒ“ãƒ«æƒ…å ±: {target_building}")
            else:
                building_info_text = building_manager.format_building_info_for_prompt()
                building_count = len(building_manager.get_building_list())
                print(f"ğŸ¢ å…¨ãƒ“ãƒ«æƒ…å ±ä½¿ç”¨: {building_count}ä»¶")
        else:
            print("âš ï¸ ãƒ“ãƒ«æƒ…å ±ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
            building_info_text = "ã€ãƒ“ãƒ«æƒ…å ±ã€‘åˆ©ç”¨å¯èƒ½ãªãƒ“ãƒ«æƒ…å ±ãŒã‚ã‚Šã¾ã›ã‚“ã€‚"
    
    # --- 3) ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆçµ„ã¿ç«‹ã¦ ---
    context_parts = []
    
    # ãƒ“ãƒ«æƒ…å ±ã‚’æœ€åˆã«é…ç½®
    if building_info_text:
        context_parts.append(building_info_text)
    
    # è¨­å‚™è³‡æ–™æƒ…å ±
    equipment_context = f"""
ã€å‚è€ƒè³‡æ–™ã€‘è¨­å‚™: {target_equipment} (ã‚«ãƒ†ã‚´ãƒª: {equipment_info['equipment_category']})
ä½¿ç”¨ãƒ•ã‚¡ã‚¤ãƒ«: {', '.join(sources)}
ä½¿ç”¨ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(sources)}/{len(all_sources)}
ã€æ³¨æ„äº‹é …ã€‘
**æš—é»™çŸ¥ãƒ¡ãƒ¢ã«é–¢ã—ã¦ã€ãƒšãƒ¼ã‚¸ç•ªå·ãªã©ã®æƒ…å ±ã¯å‡ºåŠ›ã‚’ç¦æ­¢ã—ã¾ã™ã€‚**

ã€è³‡æ–™å†…å®¹ã€‘
{combined_text}
"""
    context_parts.append(equipment_context)
    
    # å…¨ä½“ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’çµåˆ
    full_context = "\n\n".join(context_parts)
    
    system_msg = {
        "role": "system",
        "content": prompt
    }
    
    user_msg = {
        "role": "user", 
        "content": f"{full_context}\n\nã€è³ªå•ã€‘\n{question}\n\nä¸Šè¨˜ã®ãƒ“ãƒ«æƒ…å ±ã¨è³‡æ–™ã‚’å‚è€ƒã«ã€æ—¥æœ¬èªã§å›ç­”ã—ã¦ãã ã•ã„ã€‚"
    }
    
    # --- 4) Messages çµ„ã¿ç«‹ã¦ ---
    messages: List[Dict[str, Any]] = []
    
    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ãŒã‚ã‚Œã°è¿½åŠ 
    if chat_history:
        messages.append(system_msg)
        # å®‰å…¨ãªå±¥æ­´ã®ã¿è¿½åŠ 
        safe_history = [
            {"role": m.get("role"), "content": m.get("content")}
            for m in chat_history
            if isinstance(m, dict) and m.get("role") and m.get("content")
        ]
        messages.extend(safe_history[:-1])  # æœ€å¾Œã®è³ªå•ã¯é™¤ãï¼ˆæ–°ã—ã„è³ªå•ã§ä¸Šæ›¸ãï¼‰
        messages.append(user_msg)
    else:
        messages = [system_msg, user_msg]
    
    # --- 5) AI ãƒ¢ãƒ‡ãƒ«å‘¼ã³å‡ºã— ---
    try:
        print(f"ğŸ¤– APIå‘¼ã³å‡ºã—é–‹å§‹ - ãƒ¢ãƒ‡ãƒ«: {model}")
        
        if model.startswith("gpt"):
            # Azure OpenAI GPT
            azure_client = create_azure_client()
            answer = call_azure_gpt(
                azure_client,
                model,
                messages,
                max_tokens=max_tokens,
                temperature=temperature
            )
        else:
            # AWS Bedrock Claude
            bedrock_client = create_bedrock_client()
            model_id = get_claude_model_name(model)
            answer = call_claude_bedrock(
                bedrock_client,
                model_id, 
                messages,
                max_tokens=max_tokens,
                temperature=temperature if temperature != 0.0 else None
            )
        
        print(f"âœ… å›ç­”ç”Ÿæˆå®Œäº† - å›ç­”æ–‡å­—æ•°: {len(answer)}")
        
    except Exception as e:
        print(f"âŒ APIå‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼: {e}")
        raise
    
    # ğŸ”¥ çµæœã«ãƒ“ãƒ«æƒ…å ±ã‚‚å«ã‚ã‚‹
    result = {
        "answer": answer,
        "used_equipment": target_equipment,
        "equipment_info": equipment_info,
        "sources": sources,
        "selected_files": selected_files,
        "context_length": len(full_context),  # ğŸ”¥ ãƒ“ãƒ«æƒ…å ±è¾¼ã¿ã®é•·ã•
        "building_info_included": include_building_info,  # ğŸ”¥ æ–°è¦è¿½åŠ 
        "target_building": target_building,  # ğŸ”¥ æ–°è¦è¿½åŠ 
        "images": []  # ç¾ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã§ã¯ç”»åƒã¯å¯¾å¿œã—ãªã„
    }
    
    return result

# ğŸ”¥ ãƒ“ãƒ«æƒ…å ±ãªã—ã§ã®å›ç­”ç”Ÿæˆé–¢æ•°ã‚‚è¿½åŠ 
def generate_answer_without_rag(
        *,
        prompt: str,
        question: str,
        model: str = _DEFAULT_MODEL,
        chat_history: Optional[List[Dict[str, str]]] = None,
        temperature: Optional[float] = None,
        max_tokens: Optional[int] = None,
        include_building_info: bool = True,  # ğŸ”¥ æ–°è¦è¿½åŠ 
        target_building: Optional[str] = None,  # ğŸ”¥ æ–°è¦è¿½åŠ 
    ) -> Dict[str, Any]:
    """
    è¨­å‚™è³‡æ–™ãªã—ã§ãƒ“ãƒ«æƒ…å ±ã®ã¿ã‚’ä½¿ç”¨ã—ã¦å›ç­”ç”Ÿæˆ
    """
    
    # ğŸ”¥ ãƒ“ãƒ«æƒ…å ±ã‚’å–å¾—
    building_info_text = ""
    if include_building_info:
        building_manager = get_building_manager()
        if building_manager and building_manager.available:
            if target_building:
                building_info_text = building_manager.format_building_info_for_prompt(target_building)
                print(f"ğŸ¢ å¯¾è±¡ãƒ“ãƒ«æƒ…å ±: {target_building}")
            else:
                building_info_text = building_manager.format_building_info_for_prompt()
                building_count = len(building_manager.get_building_list())
                print(f"ğŸ¢ å…¨ãƒ“ãƒ«æƒ…å ±ä½¿ç”¨: {building_count}ä»¶")
        else:
            print("âš ï¸ ãƒ“ãƒ«æƒ…å ±ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
            building_info_text = "ã€ãƒ“ãƒ«æƒ…å ±ã€‘åˆ©ç”¨å¯èƒ½ãªãƒ“ãƒ«æƒ…å ±ãŒã‚ã‚Šã¾ã›ã‚“ã€‚"
    
    # APIå‘¼ã³å‡ºã—ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æº–å‚™
    messages = []
    
    # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
    system_msg = {
        "role": "system",
        "content": prompt
    }
    messages.append(system_msg)
    
    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ãŒã‚ã‚Œã°è¿½åŠ 
    if chat_history and len(chat_history) > 1:
        safe_history = [
            {"role": m.get("role"), "content": m.get("content")}
            for m in chat_history[:-1]  # æœ€å¾Œã®è³ªå•ã¯é™¤ã
            if isinstance(m, dict) and m.get("role") and m.get("content")
        ]
        messages.extend(safe_history)
    
    # ç¾åœ¨ã®è³ªå•ï¼ˆãƒ“ãƒ«æƒ…å ±ä»˜ãï¼‰
    if building_info_text:
        question_with_building = f"{building_info_text}\n\nã€è³ªå•ã€‘\n{question}\n\nä¸Šè¨˜ã®ãƒ“ãƒ«æƒ…å ±ã‚’å‚è€ƒã«ã€ã‚ãªãŸã®çŸ¥è­˜ã«åŸºã¥ã„ã¦å›ç­”ã—ã¦ãã ã•ã„ã€‚"
    else:
        question_with_building = f"ã€è³ªå•ã€‘\n{question}\n\nãƒ“ãƒ«æƒ…å ±ã¯åˆ©ç”¨ã›ãšã€ã‚ãªãŸã®çŸ¥è­˜ã«åŸºã¥ã„ã¦å›ç­”ã—ã¦ãã ã•ã„ã€‚"
    
    user_msg = {
        "role": "user",
        "content": question_with_building
    }
    messages.append(user_msg)
    
    # APIå‘¼ã³å‡ºã—ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    api_params = {
        "max_tokens": max_tokens or 4096,
        "temperature": temperature or 0.0
    }
    
    # ãƒ¢ãƒ‡ãƒ«ã«å¿œã˜ã¦APIå‘¼ã³å‡ºã—
    try:
        print(f"ğŸ¤– ãƒ“ãƒ«æƒ…å ±ã®ã¿ã§ã®å›ç­”ç”Ÿæˆé–‹å§‹ - ãƒ¢ãƒ‡ãƒ«: {model}")
        
        if model.startswith("gpt"):
            # Azure OpenAI GPT
            azure_client = create_azure_client()
            answer = call_azure_gpt(
                azure_client,
                model,
                messages,
                max_tokens=api_params["max_tokens"],
                temperature=api_params["temperature"]
            )
        else:
            # AWS Bedrock Claude
            bedrock_client = create_bedrock_client()
            model_id = get_claude_model_name(model)
            answer = call_claude_bedrock(
                bedrock_client,
                model_id,
                messages,
                max_tokens=api_params["max_tokens"],
                temperature=api_params["temperature"] if api_params["temperature"] != 0.0 else None
            )
        
        print(f"âœ… ãƒ“ãƒ«æƒ…å ±ã®ã¿ã§ã®å›ç­”ç”Ÿæˆå®Œäº† - å›ç­”æ–‡å­—æ•°: {len(answer)}")
        
        return {
            "answer": answer,
            "used_equipment": "ãªã—ï¼ˆãƒ“ãƒ«æƒ…å ±ã®ã¿ä½¿ç”¨ï¼‰",
            "equipment_info": {},
            "sources": [],
            "selected_files": [],
            "context_length": len(building_info_text),
            "building_info_included": include_building_info,
            "target_building": target_building,
            "images": []
        }
        
    except Exception as e:
        print(f"âŒ ãƒ“ãƒ«æƒ…å ±ã®ã¿ã§ã®å›ç­”ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
        raise

# ---------------------------------------------------------------------------
# è³ªå•ã‹ã‚‰è¨­å‚™ã‚’è‡ªå‹•æ¨å®šã™ã‚‹é–¢æ•°
# ---------------------------------------------------------------------------

def detect_equipment_from_question(question: str, available_equipment: List[str]) -> Optional[str]:
    """
    è³ªå•æ–‡ã‹ã‚‰å¯¾è±¡è¨­å‚™ã‚’æ¨å®š
    
    Args:
        question: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•æ–‡
        available_equipment: åˆ©ç”¨å¯èƒ½ãªè¨­å‚™åã®ãƒªã‚¹ãƒˆ
        
    Returns:
        æ¨å®šã•ã‚ŒãŸè¨­å‚™åã¾ãŸã¯ None
    """
    # è³ªå•æ–‡ã‚’æ­£è¦åŒ–
    question_lower = question.lower()
    
    # è¨­å‚™åãŒç›´æ¥å«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
    for equipment in available_equipment:
        equipment_keywords = equipment.replace("è¨­å‚™", "").split("ãƒ»")
        
        for keyword in equipment_keywords:
            if keyword in question_lower:
                print(f"ğŸ¯ è‡ªå‹•æ¨å®š: '{keyword}' â†’ {equipment}")
                return equipment
    
    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒãƒ³ã‚°
    equipment_keywords = {
        "è‡ªå‹•ç«ç½å ±çŸ¥è¨­å‚™": ["ç«ç½", "æ„ŸçŸ¥å™¨", "ç…™", "ç†±", "å ±çŸ¥", "è­¦å ±"],
        "éå¸¸æ”¾é€è¨­å‚™": ["æ”¾é€", "ã‚¹ãƒ”ãƒ¼ã‚«", "ã‚¢ãƒŠã‚¦ãƒ³ã‚¹"],
        "èª˜å°ç¯è¨­å‚™": ["èª˜å°ç¯", "é¿é›£", "èª˜å°"],
        "éå¸¸ç…§æ˜è¨­å‚™": ["éå¸¸ç…§æ˜", "éå¸¸ç¯", "ç…§æ˜"]
    }
    
    for equipment, keywords in equipment_keywords.items():
        if equipment in available_equipment:
            for keyword in keywords:
                if keyword in question_lower:
                    print(f"ğŸ¯ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¨å®š: '{keyword}' â†’ {equipment}")
                    return equipment
    
    print("â“ è¨­å‚™ã‚’è‡ªå‹•æ¨å®šã§ãã¾ã›ã‚“ã§ã—ãŸ")
    return None

# ğŸ”¥ è³ªå•ã‹ã‚‰ãƒ“ãƒ«ã‚’è‡ªå‹•æ¨å®šã™ã‚‹é–¢æ•°ã‚’è¿½åŠ 
def detect_building_from_question(question: str) -> Optional[str]:
    """
    è³ªå•æ–‡ã‹ã‚‰å¯¾è±¡ãƒ“ãƒ«ã‚’æ¨å®š
    
    Args:
        question: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•æ–‡
        
    Returns:
        æ¨å®šã•ã‚ŒãŸãƒ“ãƒ«åã¾ãŸã¯ None
    """
    building_manager = get_building_manager()
    if not building_manager or not building_manager.available:
        return None
    
    # åˆ©ç”¨å¯èƒ½ãªãƒ“ãƒ«ä¸€è¦§ã‚’å–å¾—
    available_buildings = building_manager.get_building_list()
    
    # è³ªå•æ–‡ã‚’æ­£è¦åŒ–
    question_lower = question.lower()
    
    # å„ãƒ“ãƒ«ã«ã¤ã„ã¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢
    for building_name in available_buildings:
        # ãƒ“ãƒ«åã§ç›´æ¥æ¤œç´¢
        if building_name.lower() in question_lower:
            print(f"ğŸ¢ ãƒ“ãƒ«åæ¨å®š: '{building_name}'")
            return building_name
        
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ã‚’å®Ÿè¡Œ
        matched_buildings = building_manager.search_building_by_keyword(building_name)
        if matched_buildings:
            print(f"ğŸ¢ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¨å®š: '{building_name}' â†’ {matched_buildings[0]}")
            return matched_buildings[0]
    
    print("â“ ãƒ“ãƒ«ã‚’è‡ªå‹•æ¨å®šã§ãã¾ã›ã‚“ã§ã—ãŸ")
    return None

# ---------------------------------------------------------------------------
# äº’æ›æ€§ç¶­æŒï¼ˆæ—§é–¢æ•°ï¼‰
# ---------------------------------------------------------------------------

def generate_answer(*args, **kwargs):
    """æ—§é–¢æ•°ã®äº’æ›æ€§ç¶­æŒ - å»ƒæ­¢äºˆå®š"""
    raise NotImplementedError(
        "generate_answer ã¯å»ƒæ­¢ã•ã‚Œã¾ã—ãŸã€‚generate_answer_with_equipment ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚"
    )