# src/rag_qa.py - AWS Bedrock Claudeç‰ˆ

from __future__ import annotations
from typing import List, Dict, Any, Optional
import boto3
import json
import os

try:
    import streamlit as st
    STREAMLIT_AVAILABLE = True
except ImportError:
    STREAMLIT_AVAILABLE = False

# ---------------------------------------------------------------------------
# AWS Bedrockè¨­å®š
# ---------------------------------------------------------------------------
def create_bedrock_client():
    """AWS Bedrock ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ä½œæˆ"""
    if STREAMLIT_AVAILABLE:
        try:
            aws_access_key_id = st.secrets.get("AWS_ACCESS_KEY_ID", os.getenv("AWS_ACCESS_KEY_ID"))
            aws_secret_access_key = st.secrets.get("AWS_SECRET_ACCESS_KEY", os.getenv("AWS_SECRET_ACCESS_KEY"))
            aws_region = st.secrets.get("AWS_REGION", os.getenv("AWS_REGION", "us-east-1"))
        except:
            aws_access_key_id = os.getenv("AWS_ACCESS_KEY_ID")
            aws_secret_access_key = os.getenv("AWS_SECRET_ACCESS_KEY")
            aws_region = os.getenv("AWS_REGION", "us-east-1")
    else:
        aws_access_key_id = os.getenv("AWS_ACCESS_KEY_ID")
        aws_secret_access_key = os.getenv("AWS_SECRET_ACCESS_KEY")
        aws_region = os.getenv("AWS_REGION", "us-east-1")
    
    if not aws_access_key_id or not aws_secret_access_key:
        raise ValueError("AWS Bedrock ã®è¨­å®šãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚ç’°å¢ƒå¤‰æ•°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    
    return boto3.client(
        'bedrock-runtime',
        aws_access_key_id=aws_access_key_id,
        aws_secret_access_key=aws_secret_access_key,
        region_name=aws_region
    )

# Claudeç”¨ã®ãƒ¢ãƒ‡ãƒ«åãƒãƒƒãƒ”ãƒ³ã‚°
CLAUDE_MODEL_MAPPING = {
    "claude-4-sonnet": "apac.anthropic.claude-sonnet-4-20250514-v1:0",
    "claude-3.7": "apac.anthropic.claude-3-7-sonnet-20250219-v1:0"
}

def get_claude_model_name(model_name: str) -> str:
    """Claudeè¡¨ç¤ºåã‚’Bedrockãƒ¢ãƒ‡ãƒ«IDã«å¤‰æ›"""
    return CLAUDE_MODEL_MAPPING.get(model_name, model_name)

def call_claude_bedrock(client, model_id: str, messages: List[Dict], temperature: float = None):
    """AWS Bedrock Converse APIçµŒç”±ã§Claudeã‚’å‘¼ã³å‡ºã—ï¼ˆmax_tokensã¯ãƒ¢ãƒ‡ãƒ«ä¸Šé™ï¼‰"""
    
    # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å½¢å¼ã‚’Converse APIã«åˆã‚ã›ã¦å¤‰æ›
    system_prompts = []
    conversation_messages = []
    
    for msg in messages:
        if msg["role"] == "system":
            system_prompts.append({"text": msg["content"]})
        else:
            conversation_messages.append({
                "role": msg["role"],
                "content": [{"text": msg["content"]}]
            })
    
    # Converse APIç”¨ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ§‹ç¯‰ï¼ˆmax_tokensã¯æŒ‡å®šã—ãªã„ï¼ãƒ¢ãƒ‡ãƒ«ä¸Šé™ï¼‰
    converse_params = {
        "modelId": model_id,
        "messages": conversation_messages,
        "inferenceConfig": {}
    }
    
    # temperatureãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã®ã¿è¨­å®š
    if temperature is not None and temperature != 0.0:
        converse_params["inferenceConfig"]["temperature"] = temperature
    
    # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒã‚ã‚‹å ´åˆã¯è¿½åŠ 
    if system_prompts:
        converse_params["system"] = system_prompts
    
    # Converse APIå‘¼ã³å‡ºã—
    response = client.converse(**converse_params)
    
    return response['output']['message']['content'][0]['text']

# ---------------------------------------------------------------------------
# è¨­å®š
# ---------------------------------------------------------------------------
_DEFAULT_MODEL = "claude-4-sonnet"

# ---------------------------------------------------------------------------
# å›ç­”ç”Ÿæˆï¼ˆè¨­å‚™å…¨æ–‡æŠ•å…¥ç‰ˆï¼‰
# ---------------------------------------------------------------------------

def generate_answer_with_equipment(
        *,
        prompt: str,
        question: str,
        equipment_data: Dict[str, Dict[str, Any]],
        target_equipment: str,
        selected_files: Optional[List[str]] = None,
        model: str = _DEFAULT_MODEL,
        chat_history: Optional[List[Dict[str, str]]] = None,
        temperature: Optional[float] = None,
    ) -> Dict[str, Any]:
    """
    æŒ‡å®šã•ã‚ŒãŸè¨­å‚™ã®é¸æŠãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«æŠ•å…¥ã—ã¦Claudeã§å›ç­”ã‚’ç”Ÿæˆ
    
    Args:
        prompt: ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        question: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•
        equipment_data: è¨­å‚™ãƒ‡ãƒ¼ã‚¿è¾æ›¸ï¼ˆpreprocess_filesã®å‡ºåŠ›ï¼‰
        target_equipment: å¯¾è±¡è¨­å‚™å
        selected_files: ä½¿ç”¨ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«åã®ãƒªã‚¹ãƒˆï¼ˆNoneãªã‚‰å…¨ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰
        model: ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«
        chat_history: ãƒãƒ£ãƒƒãƒˆå±¥æ­´
        temperature: æ¸©åº¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        max_tokens: æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°
    
    Returns:
        å›ç­”çµæœè¾æ›¸
    """
    # AWS Bedrock ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ä½œæˆ
    client = create_bedrock_client()

    # --- 1) æŒ‡å®šè¨­å‚™ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾— ---
    if target_equipment not in equipment_data:
        available_equipment = list(equipment_data.keys())
        raise ValueError(f"è¨­å‚™ '{target_equipment}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚åˆ©ç”¨å¯èƒ½ãªè¨­å‚™: {available_equipment}")
    
    equipment_info = equipment_data[target_equipment]
    available_files = equipment_info["files"]  # ãƒ•ã‚¡ã‚¤ãƒ«å â†’ ãƒ†ã‚­ã‚¹ãƒˆã®è¾æ›¸
    all_sources = equipment_info["sources"]
    
    # ğŸ”¥ é¸æŠã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ã‚’çµåˆ
    if selected_files is not None:
        print(f"ğŸ”§ ä½¿ç”¨è¨­å‚™: {target_equipment}")
        print(f"ğŸ“„ é¸æŠãƒ•ã‚¡ã‚¤ãƒ«: {', '.join(selected_files)}")
        print(f"ğŸ“„ åˆ©ç”¨å¯èƒ½ãƒ•ã‚¡ã‚¤ãƒ«: {', '.join(all_sources)}")
        
        # é¸æŠã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’çµåˆ
        selected_texts = []
        actual_sources = []
        
        for file_name in selected_files:
            if file_name in available_files:
                selected_texts.append(available_files[file_name])
                actual_sources.append(file_name)
            else:
                print(f"âš ï¸ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_name}")
        
        if not selected_texts:
            raise ValueError(f"é¸æŠã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ{', '.join(selected_files)}ï¼‰ãŒè¨­å‚™ãƒ‡ãƒ¼ã‚¿ã«è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        
        combined_text = "\n\n".join(selected_texts)
        sources = actual_sources
        
        print(f"ğŸ“ çµåˆå¾Œæ–‡å­—æ•°: {len(combined_text)}")
        
    else:
        # å…¨ãƒ•ã‚¡ã‚¤ãƒ«ä½¿ç”¨
        selected_texts = list(available_files.values())
        combined_text = "\n\n".join(selected_texts)
        sources = all_sources
        
        print(f"ğŸ”§ ä½¿ç”¨è¨­å‚™: {target_equipment}")
        print(f"ğŸ“„ å…¨ãƒ•ã‚¡ã‚¤ãƒ«ä½¿ç”¨: {', '.join(sources)}")
        print(f"ğŸ“ çµåˆå¾Œæ–‡å­—æ•°: {len(combined_text)}")
    
    # --- 2) ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆçµ„ã¿ç«‹ã¦ ---
    equipment_context = f"""
ã€å‚è€ƒè³‡æ–™ã€‘è¨­å‚™: {target_equipment} (ã‚«ãƒ†ã‚´ãƒª: {equipment_info['equipment_category']})
ä½¿ç”¨ãƒ•ã‚¡ã‚¤ãƒ«: {', '.join(sources)}
ä½¿ç”¨ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(sources)}/{len(all_sources)}

ã€è³‡æ–™å†…å®¹ã€‘
{combined_text}
"""
    
    system_msg = {
        "role": "system",
        "content": prompt
    }
    
    user_msg = {
        "role": "user", 
        "content": f"{equipment_context}\n\nã€è³ªå•ã€‘\n{question}\n\nä¸Šè¨˜ã®è³‡æ–™ã‚’å‚è€ƒã«ã€æ—¥æœ¬èªã§å›ç­”ã—ã¦ãã ã•ã„ã€‚"
    }
    
    # --- 3) Messages çµ„ã¿ç«‹ã¦ ---
    messages: List[Dict[str, Any]] = []
    
    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ãŒã‚ã‚Œã°è¿½åŠ 
    if chat_history:
        messages.append(system_msg)
        # å®‰å…¨ãªå±¥æ­´ã®ã¿è¿½åŠ 
        safe_history = [
            {"role": m.get("role"), "content": m.get("content")}
            for m in chat_history
            if isinstance(m, dict) and m.get("role") and m.get("content")
        ]
        messages.extend(safe_history[:-1])  # æœ€å¾Œã®è³ªå•ã¯é™¤ãï¼ˆæ–°ã—ã„è³ªå•ã§ä¸Šæ›¸ãï¼‰
        messages.append(user_msg)
    else:
        messages = [system_msg, user_msg]
    
    # --- 5) AWS Bedrock å‘¼ã³å‡ºã— ---
    try:
        model_id = get_claude_model_name(model)
        print(f"ğŸ¤– APIå‘¼ã³å‡ºã—é–‹å§‹ - ãƒ¢ãƒ‡ãƒ«: {model_id}")
        answer = call_claude_bedrock(
            client,
            model_id, 
            messages,
            temperature=temperature if temperature != 0.0 else None
        )
        print(f"âœ… å›ç­”ç”Ÿæˆå®Œäº† - å›ç­”æ–‡å­—æ•°: {len(answer)}")
        
    except Exception as e:
        print(f"âŒ APIå‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼: {e}")
        raise
    
    return {
        "answer": answer,
        "used_equipment": target_equipment,
        "equipment_info": equipment_info,
        "sources": sources,
        "selected_files": selected_files,  # ğŸ”¥ é¸æŠãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã‚’è¿½åŠ 
        "context_length": len(combined_text),
        "images": []  # ç¾ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã§ã¯ç”»åƒã¯å¯¾å¿œã—ãªã„
    }

# ---------------------------------------------------------------------------
# è³ªå•ã‹ã‚‰è¨­å‚™ã‚’è‡ªå‹•æ¨å®šã™ã‚‹é–¢æ•°
# ---------------------------------------------------------------------------

def detect_equipment_from_question(question: str, available_equipment: List[str]) -> Optional[str]:
    """
    è³ªå•æ–‡ã‹ã‚‰å¯¾è±¡è¨­å‚™ã‚’æ¨å®š
    
    Args:
        question: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•æ–‡
        available_equipment: åˆ©ç”¨å¯èƒ½ãªè¨­å‚™åã®ãƒªã‚¹ãƒˆ
        
    Returns:
        æ¨å®šã•ã‚ŒãŸè¨­å‚™åã¾ãŸã¯ None
    """
    # è³ªå•æ–‡ã‚’æ­£è¦åŒ–
    question_lower = question.lower()
    
    # è¨­å‚™åãŒç›´æ¥å«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
    for equipment in available_equipment:
        equipment_keywords = equipment.replace("è¨­å‚™", "").split("ãƒ»")
        
        for keyword in equipment_keywords:
            if keyword in question_lower:
                print(f"ğŸ¯ è‡ªå‹•æ¨å®š: '{keyword}' â†’ {equipment}")
                return equipment
    
    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒãƒ³ã‚°
    equipment_keywords = {
        "è‡ªå‹•ç«ç½å ±çŸ¥è¨­å‚™": ["ç«ç½", "æ„ŸçŸ¥å™¨", "ç…™", "ç†±", "å ±çŸ¥", "è­¦å ±"],
        "éå¸¸æ”¾é€è¨­å‚™": ["æ”¾é€", "ã‚¹ãƒ”ãƒ¼ã‚«", "ã‚¢ãƒŠã‚¦ãƒ³ã‚¹"],
        "èª˜å°ç¯è¨­å‚™": ["èª˜å°ç¯", "é¿é›£", "èª˜å°"],
        "éå¸¸ç…§æ˜è¨­å‚™": ["éå¸¸ç…§æ˜", "éå¸¸ç¯", "ç…§æ˜"]
    }
    
    for equipment, keywords in equipment_keywords.items():
        if equipment in available_equipment:
            for keyword in keywords:
                if keyword in question_lower:
                    print(f"ğŸ¯ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¨å®š: '{keyword}' â†’ {equipment}")
                    return equipment
    
    print("â“ è¨­å‚™ã‚’è‡ªå‹•æ¨å®šã§ãã¾ã›ã‚“ã§ã—ãŸ")
    return None

# ---------------------------------------------------------------------------
# äº’æ›æ€§ç¶­æŒï¼ˆæ—§é–¢æ•°ï¼‰
# ---------------------------------------------------------------------------

def generate_answer(*args, **kwargs):
    """æ—§é–¢æ•°ã®äº’æ›æ€§ç¶­æŒ - å»ƒæ­¢äºˆå®š"""
    raise NotImplementedError(
        "generate_answer ã¯å»ƒæ­¢ã•ã‚Œã¾ã—ãŸã€‚generate_answer_with_equipment ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚"
    )