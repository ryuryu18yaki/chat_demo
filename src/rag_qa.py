# src/rag_qa.py - ã‚·ãƒ³ãƒ—ãƒ«ç‰ˆï¼ˆè¨­å‚™å…¨æ–‡æŠ•å…¥æ–¹å¼ï¼‰

from __future__ import annotations
from typing import List, Dict, Any, Optional
from openai import AzureOpenAI
from base64 import b64encode
import os

try:
    import streamlit as st
    STREAMLIT_AVAILABLE = True
except ImportError:
    STREAMLIT_AVAILABLE = False

# ---------------------------------------------------------------------------
# Azure OpenAIè¨­å®š
# ---------------------------------------------------------------------------
def create_azure_openai_client():
    """Azure OpenAI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ä½œæˆ"""
    if STREAMLIT_AVAILABLE:
        try:
            azure_endpoint = st.secrets.get("AZURE_OPENAI_ENDPOINT", os.getenv("AZURE_OPENAI_ENDPOINT"))
            azure_key = st.secrets.get("AZURE_OPENAI_KEY", os.getenv("AZURE_OPENAI_KEY"))
        except:
            azure_endpoint = os.getenv("AZURE_OPENAI_ENDPOINT")
            azure_key = os.getenv("AZURE_OPENAI_KEY")
    else:
        azure_endpoint = os.getenv("AZURE_OPENAI_ENDPOINT")
        azure_key = os.getenv("AZURE_OPENAI_KEY")
    
    if not azure_endpoint or not azure_key:
        raise ValueError("Azure OpenAI ã®è¨­å®šãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚ç’°å¢ƒå¤‰æ•°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    
    return AzureOpenAI(
        api_version="2025-04-01-preview",
        azure_endpoint=azure_endpoint,
        api_key=azure_key
    )

# Azureç”¨ã®ãƒ¢ãƒ‡ãƒ«åãƒãƒƒãƒ”ãƒ³ã‚°
AZURE_MODEL_MAPPING = {
    "gpt-4.1": "gpt-4.1",
    "gpt-4.1-mini": "gpt-4.1-mini", 
    "gpt-4.1-nano": "gpt-4.1-nano",
    "gpt-4o": "gpt-4o",
    "gpt-4o-mini": "gpt-4o-mini"
}

def get_azure_model_name(model_name: str) -> str:
    """OpenAIãƒ¢ãƒ‡ãƒ«åã‚’Azureãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆåã«å¤‰æ›"""
    return AZURE_MODEL_MAPPING.get(model_name, model_name)

# ---------------------------------------------------------------------------
# è¨­å®š
# ---------------------------------------------------------------------------
_DEFAULT_MODEL = "gpt-4o-mini"

# ---------------------------------------------------------------------------
# å›ç­”ç”Ÿæˆï¼ˆè¨­å‚™å…¨æ–‡æŠ•å…¥ç‰ˆï¼‰
# ---------------------------------------------------------------------------

def generate_answer_with_equipment(
        *,
        prompt: str,
        question: str,
        equipment_data: Dict[str, Dict[str, Any]],
        target_equipment: str,
        selected_files: Optional[List[str]] = None,  # ğŸ”¥ æ–°è¦è¿½åŠ 
        model: str = _DEFAULT_MODEL,
        chat_history: Optional[List[Dict[str, str]]] = None,
        temperature: Optional[float] = None,
        max_tokens: Optional[int] = None,
    ) -> Dict[str, Any]:
    """
    æŒ‡å®šã•ã‚ŒãŸè¨­å‚™ã®é¸æŠãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«æŠ•å…¥ã—ã¦å›ç­”ã‚’ç”Ÿæˆ
    
    Args:
        prompt: ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        question: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•
        equipment_data: è¨­å‚™ãƒ‡ãƒ¼ã‚¿è¾æ›¸ï¼ˆpreprocess_filesã®å‡ºåŠ›ï¼‰
        target_equipment: å¯¾è±¡è¨­å‚™å
        selected_files: ä½¿ç”¨ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«åã®ãƒªã‚¹ãƒˆï¼ˆNoneãªã‚‰å…¨ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰
        model: ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«
        chat_history: ãƒãƒ£ãƒƒãƒˆå±¥æ­´
        temperature: æ¸©åº¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        max_tokens: æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°
    
    Returns:
        å›ç­”çµæœè¾æ›¸
    """
    # Azure OpenAI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ä½œæˆ
    client = create_azure_openai_client()

    # --- 1) æŒ‡å®šè¨­å‚™ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾— ---
    if target_equipment not in equipment_data:
        available_equipment = list(equipment_data.keys())
        raise ValueError(f"è¨­å‚™ '{target_equipment}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚åˆ©ç”¨å¯èƒ½ãªè¨­å‚™: {available_equipment}")
    
    equipment_info = equipment_data[target_equipment]
    available_files = equipment_info["files"]  # ãƒ•ã‚¡ã‚¤ãƒ«å â†’ ãƒ†ã‚­ã‚¹ãƒˆã®è¾æ›¸
    all_sources = equipment_info["sources"]
    
    # ğŸ”¥ é¸æŠã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ã‚’çµåˆ
    if selected_files is not None:
        print(f"ğŸ”§ ä½¿ç”¨è¨­å‚™: {target_equipment}")
        print(f"ğŸ“„ é¸æŠãƒ•ã‚¡ã‚¤ãƒ«: {', '.join(selected_files)}")
        print(f"ğŸ“„ åˆ©ç”¨å¯èƒ½ãƒ•ã‚¡ã‚¤ãƒ«: {', '.join(all_sources)}")
        
        # é¸æŠã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’çµåˆ
        selected_texts = []
        actual_sources = []
        
        for file_name in selected_files:
            if file_name in available_files:
                selected_texts.append(available_files[file_name])
                actual_sources.append(file_name)
            else:
                print(f"âš ï¸ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_name}")
        
        if not selected_texts:
            raise ValueError(f"é¸æŠã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ{', '.join(selected_files)}ï¼‰ãŒè¨­å‚™ãƒ‡ãƒ¼ã‚¿ã«è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        
        combined_text = "\n\n".join(selected_texts)
        sources = actual_sources
        
        print(f"ğŸ“ çµåˆå¾Œæ–‡å­—æ•°: {len(combined_text)}")
        
    else:
        # å…¨ãƒ•ã‚¡ã‚¤ãƒ«ä½¿ç”¨
        selected_texts = list(available_files.values())
        combined_text = "\n\n".join(selected_texts)
        sources = all_sources
        
        print(f"ğŸ”§ ä½¿ç”¨è¨­å‚™: {target_equipment}")
        print(f"ğŸ“„ å…¨ãƒ•ã‚¡ã‚¤ãƒ«ä½¿ç”¨: {', '.join(sources)}")
        print(f"ğŸ“ çµåˆå¾Œæ–‡å­—æ•°: {len(combined_text)}")
    
    # --- 2) ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆçµ„ã¿ç«‹ã¦ ---
    equipment_context = f"""
ã€å‚è€ƒè³‡æ–™ã€‘è¨­å‚™: {target_equipment} (ã‚«ãƒ†ã‚´ãƒª: {equipment_info['equipment_category']})
ä½¿ç”¨ãƒ•ã‚¡ã‚¤ãƒ«: {', '.join(sources)}
ä½¿ç”¨ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(sources)}/{len(all_sources)}

ã€è³‡æ–™å†…å®¹ã€‘
{combined_text}
"""
    
    system_msg = {
        "role": "system",
        "content": prompt
    }
    
    user_msg = {
        "role": "user", 
        "content": f"{equipment_context}\n\nã€è³ªå•ã€‘\n{question}\n\nä¸Šè¨˜ã®è³‡æ–™ã‚’å‚è€ƒã«ã€æ—¥æœ¬èªã§å›ç­”ã—ã¦ãã ã•ã„ã€‚"
    }
    
    # --- 3) Messages çµ„ã¿ç«‹ã¦ ---
    messages: List[Dict[str, Any]] = []
    
    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ãŒã‚ã‚Œã°è¿½åŠ 
    if chat_history:
        messages.append(system_msg)
        # å®‰å…¨ãªå±¥æ­´ã®ã¿è¿½åŠ 
        safe_history = [
            {"role": m.get("role"), "content": m.get("content")}
            for m in chat_history
            if isinstance(m, dict) and m.get("role") and m.get("content")
        ]
        messages.extend(safe_history[:-1])  # æœ€å¾Œã®è³ªå•ã¯é™¤ãï¼ˆæ–°ã—ã„è³ªå•ã§ä¸Šæ›¸ãï¼‰
        messages.append(user_msg)
    else:
        messages = [system_msg, user_msg]
    
    # --- 4) APIå‘¼ã³å‡ºã—ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ§‹ç¯‰ ---
    params = {
        "model": get_azure_model_name(model),
        "messages": messages,
    }
    
    if temperature is not None:
        params["temperature"] = temperature
    if max_tokens is not None:
        params["max_tokens"] = max_tokens
    
    # --- 5) Azure OpenAI å‘¼ã³å‡ºã— ---
    try:
        print(f"ğŸ¤– APIå‘¼ã³å‡ºã—é–‹å§‹ - ãƒ¢ãƒ‡ãƒ«: {get_azure_model_name(model)}")
        resp = client.chat.completions.create(**params)
        answer = resp.choices[0].message.content
        print(f"âœ… å›ç­”ç”Ÿæˆå®Œäº† - å›ç­”æ–‡å­—æ•°: {len(answer)}")
        
    except Exception as e:
        print(f"âŒ APIå‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼: {e}")
        raise
    
    return {
        "answer": answer,
        "used_equipment": target_equipment,
        "equipment_info": equipment_info,
        "sources": sources,
        "selected_files": selected_files,  # ğŸ”¥ é¸æŠãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã‚’è¿½åŠ 
        "context_length": len(combined_text),
        "images": []  # ç¾ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã§ã¯ç”»åƒã¯å¯¾å¿œã—ãªã„
    }

# ---------------------------------------------------------------------------
# è³ªå•ã‹ã‚‰è¨­å‚™ã‚’è‡ªå‹•æ¨å®šã™ã‚‹é–¢æ•°
# ---------------------------------------------------------------------------

def detect_equipment_from_question(question: str, available_equipment: List[str]) -> Optional[str]:
    """
    è³ªå•æ–‡ã‹ã‚‰å¯¾è±¡è¨­å‚™ã‚’æ¨å®š
    
    Args:
        question: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•æ–‡
        available_equipment: åˆ©ç”¨å¯èƒ½ãªè¨­å‚™åã®ãƒªã‚¹ãƒˆ
        
    Returns:
        æ¨å®šã•ã‚ŒãŸè¨­å‚™åã¾ãŸã¯ None
    """
    # è³ªå•æ–‡ã‚’æ­£è¦åŒ–
    question_lower = question.lower()
    
    # è¨­å‚™åãŒç›´æ¥å«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
    for equipment in available_equipment:
        equipment_keywords = equipment.replace("è¨­å‚™", "").split("ãƒ»")
        
        for keyword in equipment_keywords:
            if keyword in question_lower:
                print(f"ğŸ¯ è‡ªå‹•æ¨å®š: '{keyword}' â†’ {equipment}")
                return equipment
    
    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒãƒ³ã‚°
    equipment_keywords = {
        "è‡ªå‹•ç«ç½å ±çŸ¥è¨­å‚™": ["ç«ç½", "æ„ŸçŸ¥å™¨", "ç…™", "ç†±", "å ±çŸ¥", "è­¦å ±"],
        "éå¸¸æ”¾é€è¨­å‚™": ["æ”¾é€", "ã‚¹ãƒ”ãƒ¼ã‚«", "ã‚¢ãƒŠã‚¦ãƒ³ã‚¹"],
        "èª˜å°ç¯è¨­å‚™": ["èª˜å°ç¯", "é¿é›£", "èª˜å°"],
        "éå¸¸ç…§æ˜è¨­å‚™": ["éå¸¸ç…§æ˜", "éå¸¸ç¯", "ç…§æ˜"]
    }
    
    for equipment, keywords in equipment_keywords.items():
        if equipment in available_equipment:
            for keyword in keywords:
                if keyword in question_lower:
                    print(f"ğŸ¯ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¨å®š: '{keyword}' â†’ {equipment}")
                    return equipment
    
    print("â“ è¨­å‚™ã‚’è‡ªå‹•æ¨å®šã§ãã¾ã›ã‚“ã§ã—ãŸ")
    return None

# ---------------------------------------------------------------------------
# äº’æ›æ€§ç¶­æŒï¼ˆæ—§é–¢æ•°ï¼‰
# ---------------------------------------------------------------------------

def generate_answer(*args, **kwargs):
    """æ—§é–¢æ•°ã®äº’æ›æ€§ç¶­æŒ - å»ƒæ­¢äºˆå®š"""
    raise NotImplementedError(
        "generate_answer ã¯å»ƒæ­¢ã•ã‚Œã¾ã—ãŸã€‚generate_answer_with_equipment ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚"
    )