# src/langchain_models.py

import os
from typing import Union, Optional
from langchain_anthropic import ChatAnthropic
from langchain_openai import AzureChatOpenAI
from langchain_core.language_models.chat_models import BaseChatModel

try:
    import streamlit as st
    STREAMLIT_AVAILABLE = True
except ImportError:
    STREAMLIT_AVAILABLE = False

from src.logging_utils import init_logger
logger = init_logger()

# Claudeç”¨ã®ãƒ¢ãƒ‡ãƒ«åãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆæ—¢å­˜ã¨åŒã˜ï¼‰
CLAUDE_MODEL_MAPPING = {
    "claude-4-sonnet": "claude-3-5-sonnet-20241022",  # å®Ÿéš›ã«åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«åã«èª¿æ•´
    "claude-3.7": "claude-3-haiku-20240307"  # å®Ÿéš›ã«åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«åã«èª¿æ•´
}

# Azure OpenAIç”¨ã®ãƒ¢ãƒ‡ãƒ«åãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆæ—¢å­˜ã¨åŒã˜ï¼‰
AZURE_MODEL_MAPPING = {
    "gpt-4.1": "gpt-4",
    "gpt-4o": "gpt-4o"
}

class ModelManager:
    """LangChainç”¨ã®ãƒ¢ãƒ‡ãƒ«ç®¡ç†ã‚¯ãƒ©ã‚¹"""
    
    @staticmethod
    def get_credentials() -> dict:
        """èªè¨¼æƒ…å ±ã‚’å–å¾—ï¼ˆæ—¢å­˜ã®app.pyã®ãƒ­ã‚¸ãƒƒã‚¯ã¨å®Œå…¨ã«åŒã˜ï¼‰"""
        credentials = {}
        
        if STREAMLIT_AVAILABLE:
            # === AWS Bedrockè¨­å®šï¼ˆapp.pyã¨åŒã˜ãƒ­ã‚¸ãƒƒã‚¯ï¼‰ ===
            try:
                credentials["aws_access_key_id"] = st.secrets.get("AWS_ACCESS_KEY_ID", os.getenv("AWS_ACCESS_KEY_ID"))
                credentials["aws_secret_access_key"] = st.secrets.get("AWS_SECRET_ACCESS_KEY", os.getenv("AWS_SECRET_ACCESS_KEY"))
                credentials["aws_region"] = st.secrets.get("AWS_REGION", os.getenv("AWS_REGION", "us-east-1"))
            except:
                credentials["aws_access_key_id"] = os.getenv("AWS_ACCESS_KEY_ID")
                credentials["aws_secret_access_key"] = os.getenv("AWS_SECRET_ACCESS_KEY")
                credentials["aws_region"] = os.getenv("AWS_REGION", "us-east-1")
            
            # === Azure OpenAIè¨­å®šï¼ˆapp.pyã¨åŒã˜ãƒ­ã‚¸ãƒƒã‚¯ï¼‰ ===
            try:
                credentials["azure_endpoint"] = st.secrets.get("AZURE_OPENAI_ENDPOINT", os.getenv("AZURE_OPENAI_ENDPOINT"))
                credentials["azure_api_key"] = st.secrets.get("AZURE_OPENAI_API_KEY", os.getenv("AZURE_OPENAI_API_KEY"))
                credentials["azure_api_version"] = st.secrets.get("AZURE_OPENAI_API_VERSION", os.getenv("AZURE_OPENAI_API_VERSION", "2024-08-01-preview"))
            except:
                credentials["azure_endpoint"] = os.getenv("AZURE_OPENAI_ENDPOINT")
                credentials["azure_api_key"] = os.getenv("AZURE_OPENAI_API_KEY")
                credentials["azure_api_version"] = os.getenv("AZURE_OPENAI_API_VERSION", "2024-08-01-preview")
        else:
            # Streamlitç’°å¢ƒå¤–ã§ã¯ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—
            credentials["aws_access_key_id"] = os.getenv("AWS_ACCESS_KEY_ID")
            credentials["aws_secret_access_key"] = os.getenv("AWS_SECRET_ACCESS_KEY")
            credentials["aws_region"] = os.getenv("AWS_REGION", "us-east-1")
            credentials["azure_endpoint"] = os.getenv("AZURE_OPENAI_ENDPOINT")
            credentials["azure_api_key"] = os.getenv("AZURE_OPENAI_API_KEY")
            credentials["azure_api_version"] = os.getenv("AZURE_OPENAI_API_VERSION", "2024-08-01-preview")
        
        return credentials
    
    @staticmethod
    def create_claude_model(
        model_name: str,
        temperature: float = 0.0,
        max_tokens: Optional[int] = None
    ) -> ChatAnthropic:
        """Claude (Anthropic) ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆ"""
        credentials = ModelManager.get_credentials()
        
        if not credentials["aws_access_key_id"] or not credentials["aws_secret_access_key"]:
            raise ValueError("AWS Bedrock ã®è¨­å®šãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚ç’°å¢ƒå¤‰æ•°ã¾ãŸã¯Secrets.tomlã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        
        # ãƒ¢ãƒ‡ãƒ«åã‚’å®Ÿéš›ã®Anthropic APIãƒ¢ãƒ‡ãƒ«åã«å¤‰æ›
        actual_model = CLAUDE_MODEL_MAPPING.get(model_name, "claude-3-5-sonnet-20241022")
        
        model_kwargs = {
            "model": actual_model,
            "temperature": temperature,
            "aws_access_key_id": credentials["aws_access_key_id"],
            "aws_secret_access_key": credentials["aws_secret_access_key"],
            "aws_region": credentials["aws_region"]
        }
        
        if max_tokens is not None:
            model_kwargs["max_tokens"] = max_tokens
        
        logger.info(f"ğŸ¤– Claude LangChain modelä½œæˆ: {actual_model}, temp={temperature}, max_tokens={max_tokens}")
        
        return ChatAnthropic(**model_kwargs)
    
    @staticmethod
    def create_azure_gpt_model(
        model_name: str,
        temperature: float = 0.0,
        max_tokens: Optional[int] = None
    ) -> AzureChatOpenAI:
        """Azure OpenAI GPT ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆ"""
        credentials = ModelManager.get_credentials()
        
        if not credentials["azure_endpoint"] or not credentials["azure_api_key"]:
            raise ValueError("Azure OpenAI ã®è¨­å®šãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚ç’°å¢ƒå¤‰æ•°ã¾ãŸã¯Secrets.tomlã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        
        # ãƒ¢ãƒ‡ãƒ«åã‚’Azureãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆåã«å¤‰æ›
        azure_deployment = AZURE_MODEL_MAPPING.get(model_name, model_name)
        
        model_kwargs = {
            "azure_deployment": azure_deployment,
            "temperature": temperature,
            "azure_endpoint": credentials["azure_endpoint"],
            "api_key": credentials["azure_api_key"],
            "api_version": credentials["azure_api_version"]
        }
        
        if max_tokens is not None:
            model_kwargs["max_tokens"] = max_tokens
        
        logger.info(f"ğŸ¤– Azure GPT LangChain modelä½œæˆ: {azure_deployment}, temp={temperature}, max_tokens={max_tokens}")
        
        return AzureChatOpenAI(**model_kwargs)
    
    @staticmethod
    def get_chat_model(
        model_name: str,
        temperature: float = 0.0,
        max_tokens: Optional[int] = None
    ) -> BaseChatModel:
        """
        ãƒ¢ãƒ‡ãƒ«åã«åŸºã¥ã„ã¦é©åˆ‡ãªChatModelã‚’è¿”ã™
        
        Args:
            model_name: ãƒ¢ãƒ‡ãƒ«å (claude-4-sonnet, gpt-4oç­‰)
            temperature: æ¸©åº¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
            max_tokens: æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°
            
        Returns:
            LangChainã®ChatModel
        """
        logger.info(f"ğŸ¯ LangChain ChatModelä½œæˆé–‹å§‹: model={model_name}")
        
        if model_name.startswith("claude"):
            return ModelManager.create_claude_model(model_name, temperature, max_tokens)
        elif model_name.startswith("gpt"):
            return ModelManager.create_azure_gpt_model(model_name, temperature, max_tokens)
        else:
            raise ValueError(f"ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ãƒ¢ãƒ‡ãƒ«: {model_name}")

# ä¾¿åˆ©é–¢æ•°
def get_chat_model(
    model_name: str,
    temperature: float = 0.0,
    max_tokens: Optional[int] = None
) -> BaseChatModel:
    """ModelManager.get_chat_modelã®ä¾¿åˆ©é–¢æ•°"""
    return ModelManager.get_chat_model(model_name, temperature, max_tokens)

# äº’æ›æ€§ãƒ†ã‚¹ãƒˆç”¨é–¢æ•°
def test_model_creation():
    """ãƒ¢ãƒ‡ãƒ«ä½œæˆã®ãƒ†ã‚¹ãƒˆ"""
    try:
        logger.info("ğŸ§ª Claude model test...")
        claude_model = get_chat_model("claude-4-sonnet", temperature=0.1, max_tokens=100)
        logger.info("âœ… Claude model ä½œæˆæˆåŠŸ")
        
        logger.info("ğŸ§ª GPT model test...")
        gpt_model = get_chat_model("gpt-4o", temperature=0.1, max_tokens=100)
        logger.info("âœ… GPT model ä½œæˆæˆåŠŸ")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ Modelä½œæˆãƒ†ã‚¹ãƒˆå¤±æ•—: {e}")
        return False

if __name__ == "__main__":
    test_model_creation()