# src/langchain_models.py

import os
from typing import Union, Optional
import boto3
from langchain_aws import ChatBedrock  # â† AWS Bedrockç”¨
from langchain_openai import AzureChatOpenAI
from langchain_core.language_models.chat_models import BaseChatModel

try:
    import streamlit as st
    STREAMLIT_AVAILABLE = True
except ImportError:
    STREAMLIT_AVAILABLE = False

from src.logging_utils import init_logger
logger = init_logger()

# Claudeç”¨ã®ãƒ¢ãƒ‡ãƒ«åãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆBedrockç”¨ï¼‰
CLAUDE_MODEL_MAPPING = {
    "claude-4-sonnet": "anthropic.claude-sonnet-4-20250514-v1:0",  
    "claude-3.7": "anthropic.claude-3-7-sonnet-20250219-v1:0",     
}

# Azure OpenAIç”¨ã®ãƒ¢ãƒ‡ãƒ«åãƒãƒƒãƒ”ãƒ³ã‚°
AZURE_MODEL_MAPPING = {
    "gpt-4.1": "gpt-4.1",
    "gpt-4o": "gpt-4o"
}

class ModelManager:
    """LangChainç”¨ã®ãƒ¢ãƒ‡ãƒ«ç®¡ç†ã‚¯ãƒ©ã‚¹"""
    
    @staticmethod
    def get_credentials() -> dict:
        """èªè¨¼æƒ…å ±ã‚’å–å¾—"""
        credentials = {}
        
        if STREAMLIT_AVAILABLE:
            # === AWS Bedrockè¨­å®š ===
            try:
                credentials["aws_access_key_id"] = st.secrets.get("AWS_ACCESS_KEY_ID", os.getenv("AWS_ACCESS_KEY_ID"))
                credentials["aws_secret_access_key"] = st.secrets.get("AWS_SECRET_ACCESS_KEY", os.getenv("AWS_SECRET_ACCESS_KEY"))
                credentials["aws_region"] = st.secrets.get("AWS_REGION", os.getenv("AWS_REGION", "us-east-1"))
            except:
                credentials["aws_access_key_id"] = os.getenv("AWS_ACCESS_KEY_ID")
                credentials["aws_secret_access_key"] = os.getenv("AWS_SECRET_ACCESS_KEY")
                credentials["aws_region"] = os.getenv("AWS_REGION", "us-east-1")
            
            # === Azure OpenAIè¨­å®š ===
            try:
                credentials["azure_endpoint"] = st.secrets.get("AZURE_OPENAI_ENDPOINT", os.getenv("AZURE_OPENAI_ENDPOINT"))
                credentials["azure_api_key"] = st.secrets.get("AZURE_OPENAI_API_KEY", os.getenv("AZURE_OPENAI_API_KEY"))
                credentials["azure_api_version"] = st.secrets.get("AZURE_OPENAI_API_VERSION", os.getenv("AZURE_OPENAI_API_VERSION", "2024-08-01-preview"))
            except:
                credentials["azure_endpoint"] = os.getenv("AZURE_OPENAI_ENDPOINT")
                credentials["azure_api_key"] = os.getenv("AZURE_OPENAI_API_KEY")
                credentials["azure_api_version"] = os.getenv("AZURE_OPENAI_API_VERSION", "2024-08-01-preview")
        else:
            # Streamlitç’°å¢ƒå¤–ã§ã¯ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—
            credentials["aws_access_key_id"] = os.getenv("AWS_ACCESS_KEY_ID")
            credentials["aws_secret_access_key"] = os.getenv("AWS_SECRET_ACCESS_KEY")
            credentials["aws_region"] = os.getenv("AWS_REGION", "us-east-1")
            credentials["azure_endpoint"] = os.getenv("AZURE_OPENAI_ENDPOINT")
            credentials["azure_api_key"] = os.getenv("AZURE_OPENAI_API_KEY")
            credentials["azure_api_version"] = os.getenv("AZURE_OPENAI_API_VERSION", "2024-08-01-preview")
        
        return credentials
    
    @staticmethod
    def create_claude_model(
        model_name: str,
        temperature: float = 0.0,
        max_tokens: Optional[int] = None
    ) -> ChatBedrock:
        """Claude (AWS BedrockçµŒç”±) ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆ"""
        credentials = ModelManager.get_credentials()
        
        if not credentials["aws_access_key_id"] or not credentials["aws_secret_access_key"]:
            raise ValueError("AWS Bedrock ã®è¨­å®šãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚Streamlit Secretsã®AWSèªè¨¼æƒ…å ±ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        
        # Boto3ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ä½œæˆï¼ˆèªè¨¼æƒ…å ±ã‚’æ˜ç¤ºçš„ã«è¨­å®šï¼‰
        session = boto3.Session(
            aws_access_key_id=credentials["aws_access_key_id"],
            aws_secret_access_key=credentials["aws_secret_access_key"],
            region_name=credentials["aws_region"]
        )
        
        # Bedrock Runtimeã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ä½œæˆ
        bedrock_client = session.client('bedrock-runtime')
        
        # ãƒ¢ãƒ‡ãƒ«åã‚’Bedrockç”¨ã«å¤‰æ›
        bedrock_model_id = CLAUDE_MODEL_MAPPING.get(model_name, "anthropic.claude-sonnet-4-20250514-v1:0")
        
        # ChatBedrockã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        model_kwargs = {
            "model_id": bedrock_model_id,
            "client": bedrock_client,
            "model_kwargs": {
                "temperature": temperature,
            }
        }
        
        if max_tokens is not None:
            model_kwargs["model_kwargs"]["max_tokens"] = max_tokens
        
        logger.info(f"ğŸ¤– Claude Bedrock modelä½œæˆ: {bedrock_model_id}, temp={temperature}, max_tokens={max_tokens}, region={credentials['aws_region']}")
        
        return ChatBedrock(**model_kwargs)
    
    @staticmethod
    def create_azure_gpt_model(
        model_name: str,
        temperature: float = 0.0,
        max_tokens: Optional[int] = None
    ) -> AzureChatOpenAI:
        """Azure OpenAI GPT ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆ"""
        credentials = ModelManager.get_credentials()
        
        if not credentials["azure_endpoint"] or not credentials["azure_api_key"]:
            raise ValueError("Azure OpenAI ã®è¨­å®šãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚Streamlit Secretsã¾ãŸã¯Secrets.tomlã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        
        # ãƒ¢ãƒ‡ãƒ«åã‚’Azureãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆåã«å¤‰æ›
        azure_deployment = AZURE_MODEL_MAPPING.get(model_name, model_name)
        
        model_kwargs = {
            "azure_deployment": azure_deployment,
            "temperature": temperature,
            "azure_endpoint": credentials["azure_endpoint"],
            "api_key": credentials["azure_api_key"],
            "api_version": credentials["azure_api_version"]
        }
        
        if max_tokens is not None:
            model_kwargs["max_tokens"] = max_tokens
        
        logger.info(f"ğŸ¤– Azure GPT LangChain modelä½œæˆ: {azure_deployment}, temp={temperature}, max_tokens={max_tokens}")
        
        return AzureChatOpenAI(**model_kwargs)
    
    @staticmethod
    def get_chat_model(
        model_name: str,
        temperature: float = 0.0,
        max_tokens: Optional[int] = None
    ) -> BaseChatModel:
        """
        ãƒ¢ãƒ‡ãƒ«åã«åŸºã¥ã„ã¦é©åˆ‡ãªChatModelã‚’è¿”ã™
        
        Args:
            model_name: ãƒ¢ãƒ‡ãƒ«å (claude-4-sonnet, gpt-4oç­‰)
            temperature: æ¸©åº¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
            max_tokens: æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°
            
        Returns:
            LangChainã®ChatModel
        """
        logger.info(f"ğŸ¯ LangChain ChatModelä½œæˆé–‹å§‹: model={model_name}")
        
        if model_name.startswith("claude"):
            return ModelManager.create_claude_model(model_name, temperature, max_tokens)
        elif model_name.startswith("gpt"):
            return ModelManager.create_azure_gpt_model(model_name, temperature, max_tokens)
        else:
            raise ValueError(f"ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ãƒ¢ãƒ‡ãƒ«: {model_name}")

# ä¾¿åˆ©é–¢æ•°
def get_chat_model(
    model_name: str,
    temperature: float = 0.0,
    max_tokens: Optional[int] = None
) -> BaseChatModel:
    """ModelManager.get_chat_modelã®ä¾¿åˆ©é–¢æ•°"""
    return ModelManager.get_chat_model(model_name, temperature, max_tokens)

# äº’æ›æ€§ãƒ†ã‚¹ãƒˆç”¨é–¢æ•°
def test_model_creation():
    """ãƒ¢ãƒ‡ãƒ«ä½œæˆã®ãƒ†ã‚¹ãƒˆ"""
    try:
        logger.info("ğŸ§ª Claude Bedrock model test...")
        claude_model = get_chat_model("claude-4-sonnet", temperature=0.1, max_tokens=100)
        logger.info("âœ… Claude Bedrock model ä½œæˆæˆåŠŸ")
        
        logger.info("ğŸ§ª GPT model test...")
        gpt_model = get_chat_model("gpt-4o", temperature=0.1, max_tokens=100)
        logger.info("âœ… GPT model ä½œæˆæˆåŠŸ")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ Modelä½œæˆãƒ†ã‚¹ãƒˆå¤±æ•—: {e}")
        return False

if __name__ == "__main__":
    test_model_creation()